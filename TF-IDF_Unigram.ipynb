{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from os import path\n",
    "import re\n",
    "import string\n",
    "\n",
    "#NLTK\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from nltk.util import ngrams\n",
    "from nltk import bigrams, trigrams\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "\n",
    "#sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from statistics import mean, stdev\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "#% matplotlib inline\n",
    "\n",
    "\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "#from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "#from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory, ArrayDictionary, StopWordRemover\n",
    "\n",
    "\n",
    "#https://towardsdatascience.com/multiclass-classification-with-support-vector-machines-svm-kernel-trick-kernel-functions-f9d5377d6f02\n",
    "#https://www.analyseup.com/python-machine-learning/stratified-kfold.html\n",
    "#https://www.pluralsight.com/guides/validating-machine-learning-models-scikit-learn\n",
    "#https://www.pengalaman-edukasi.com/2020/04/apa-itu-k-fold-cross-validation.html\n",
    "#https://chrisalbon.com/code/machine_learning/support_vector_machines/svc_parameters_using_rbf_kernel/\n",
    "#https://www.analyseup.com/python-machine-learning/stratified-kfold.html\n",
    "#https://stats.stackexchange.com/questions/462363/creating-a-dataframe-includes-my-cross-validation-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"C:/Users/USER/anaconda3/Lib/site-packages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Class</th>\n",
       "      <th>Author</th>\n",
       "      <th>Normalized</th>\n",
       "      <th>Stopword</th>\n",
       "      <th>Stemmed</th>\n",
       "      <th>Tokenize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>agama</td>\n",
       "      <td>rakyat menunggu keseriusan pernyataan soal pen...</td>\n",
       "      <td>y</td>\n",
       "      <td>Bhrigutantra</td>\n",
       "      <td>rakyat menunggu keseriusan pernyataan soal pen...</td>\n",
       "      <td>rakyat menunggu keseriusan pernyataan penegaka...</td>\n",
       "      <td>rakyat tunggu serius nyata tega hukum detik la...</td>\n",
       "      <td>['rakyat', 'tunggu', 'serius', 'nyata', 'tega'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agama</td>\n",
       "      <td>baca dong klo gatau apa gausah sok bawa agama...</td>\n",
       "      <td>y</td>\n",
       "      <td>kckiranaaa</td>\n",
       "      <td>baca dong kalau tak tau apa tidak usah sok ba...</td>\n",
       "      <td>baca sok bawa agama komen sesuai pendapatmu</td>\n",
       "      <td>baca sok bawa agama komen sesuai dapat</td>\n",
       "      <td>['baca', 'sok', 'bawa', 'agama', 'komen', 'ses...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>agama</td>\n",
       "      <td>skg tokoh agama lebih memilih jabatan dan gol...</td>\n",
       "      <td>y</td>\n",
       "      <td>Lani34823852</td>\n",
       "      <td>sekarang tokoh agama lebih memilih jabatan da...</td>\n",
       "      <td>tokoh agama memilih jabatan golongan</td>\n",
       "      <td>tokoh agama pilih jabat golong</td>\n",
       "      <td>['tokoh', 'agama', 'pilih', 'jabat', 'golong']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>agama</td>\n",
       "      <td>inilah pentingnya membaca biar gasotoy menjus...</td>\n",
       "      <td>y</td>\n",
       "      <td>KCangcut</td>\n",
       "      <td>inilah pentingnya membaca biar gasotoy menjus...</td>\n",
       "      <td>membaca gasotoy menjustifikasi agama</td>\n",
       "      <td>baca gasotoy justifikasi agama</td>\n",
       "      <td>['baca', 'gasotoy', 'justifikasi', 'agama']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>agama</td>\n",
       "      <td>hot take orang yg dikit bawa zodiak ke topik a...</td>\n",
       "      <td>y</td>\n",
       "      <td>Far_away90</td>\n",
       "      <td>hot take orang yang sedikit bawa zodiak ke top...</td>\n",
       "      <td>hot take orang bawa zodiak topik apapun menyeb...</td>\n",
       "      <td>hot take orang bawa zodiak topik apa sebal ora...</td>\n",
       "      <td>['hot', 'take', 'orang', 'bawa', 'zodiak', 'to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic                                              Tweet Class  \\\n",
       "0  agama  rakyat menunggu keseriusan pernyataan soal pen...     y   \n",
       "1  agama   baca dong klo gatau apa gausah sok bawa agama...     y   \n",
       "2  agama   skg tokoh agama lebih memilih jabatan dan gol...     y   \n",
       "3  agama   inilah pentingnya membaca biar gasotoy menjus...     y   \n",
       "4  agama  hot take orang yg dikit bawa zodiak ke topik a...     y   \n",
       "\n",
       "         Author                                         Normalized  \\\n",
       "0  Bhrigutantra  rakyat menunggu keseriusan pernyataan soal pen...   \n",
       "1    kckiranaaa   baca dong kalau tak tau apa tidak usah sok ba...   \n",
       "2  Lani34823852   sekarang tokoh agama lebih memilih jabatan da...   \n",
       "3      KCangcut   inilah pentingnya membaca biar gasotoy menjus...   \n",
       "4    Far_away90  hot take orang yang sedikit bawa zodiak ke top...   \n",
       "\n",
       "                                            Stopword  \\\n",
       "0  rakyat menunggu keseriusan pernyataan penegaka...   \n",
       "1        baca sok bawa agama komen sesuai pendapatmu   \n",
       "2               tokoh agama memilih jabatan golongan   \n",
       "3               membaca gasotoy menjustifikasi agama   \n",
       "4  hot take orang bawa zodiak topik apapun menyeb...   \n",
       "\n",
       "                                             Stemmed  \\\n",
       "0  rakyat tunggu serius nyata tega hukum detik la...   \n",
       "1             baca sok bawa agama komen sesuai dapat   \n",
       "2                     tokoh agama pilih jabat golong   \n",
       "3                     baca gasotoy justifikasi agama   \n",
       "4  hot take orang bawa zodiak topik apa sebal ora...   \n",
       "\n",
       "                                            Tokenize  \n",
       "0  ['rakyat', 'tunggu', 'serius', 'nyata', 'tega'...  \n",
       "1  ['baca', 'sok', 'bawa', 'agama', 'komen', 'ses...  \n",
       "2     ['tokoh', 'agama', 'pilih', 'jabat', 'golong']  \n",
       "3        ['baca', 'gasotoy', 'justifikasi', 'agama']  \n",
       "4  ['hot', 'take', 'orang', 'bawa', 'zodiak', 'to...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data_tweet_finall_preprocess_fix2.csv\")\n",
    "df = df.drop([\"Unnamed: 0\",\"Unnamed: 0.1\"],axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Class\n",
       "0     y\n",
       "1     y\n",
       "2     y\n",
       "3     y\n",
       "4     y"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class = pd.DataFrame(df['Class'])\n",
    "df_class.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aan</th>\n",
       "      <th>aanya</th>\n",
       "      <th>abad</th>\n",
       "      <th>abadi</th>\n",
       "      <th>abai</th>\n",
       "      <th>abal</th>\n",
       "      <th>abang</th>\n",
       "      <th>abangda</th>\n",
       "      <th>abas</th>\n",
       "      <th>abbas</th>\n",
       "      <th>...</th>\n",
       "      <th>zulkarnain</th>\n",
       "      <th>zulpan</th>\n",
       "      <th>zura</th>\n",
       "      <th>zvt</th>\n",
       "      <th>zxtle</th>\n",
       "      <th>zyafhoja</th>\n",
       "      <th>zyan</th>\n",
       "      <th>zyandaru</th>\n",
       "      <th>zyk</th>\n",
       "      <th>zyn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 17943 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aan  aanya  abad  abadi  abai  abal  abang  abangda  abas  abbas  ...  \\\n",
       "0  0.0    0.0   0.0    0.0   0.0   0.0    0.0      0.0   0.0    0.0  ...   \n",
       "1  0.0    0.0   0.0    0.0   0.0   0.0    0.0      0.0   0.0    0.0  ...   \n",
       "2  0.0    0.0   0.0    0.0   0.0   0.0    0.0      0.0   0.0    0.0  ...   \n",
       "3  0.0    0.0   0.0    0.0   0.0   0.0    0.0      0.0   0.0    0.0  ...   \n",
       "4  0.0    0.0   0.0    0.0   0.0   0.0    0.0      0.0   0.0    0.0  ...   \n",
       "\n",
       "   zulkarnain  zulpan  zura  zvt  zxtle  zyafhoja  zyan  zyandaru  zyk  zyn  \n",
       "0         0.0     0.0   0.0  0.0    0.0       0.0   0.0       0.0  0.0  0.0  \n",
       "1         0.0     0.0   0.0  0.0    0.0       0.0   0.0       0.0  0.0  0.0  \n",
       "2         0.0     0.0   0.0  0.0    0.0       0.0   0.0       0.0  0.0  0.0  \n",
       "3         0.0     0.0   0.0  0.0    0.0       0.0   0.0       0.0  0.0  0.0  \n",
       "4         0.0     0.0   0.0  0.0    0.0       0.0   0.0       0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 17943 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_tfidf = TfidfVectorizer() \n",
    "X_tfidf = v_tfidf.fit_transform(df['Stemmed'].values.astype('U')) \n",
    "features = (v_tfidf.get_feature_names())\n",
    "\n",
    "data_unigram = pd.DataFrame(X_tfidf.toarray(),columns = features) \n",
    "data_unigram.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class\n",
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Label encoder\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "df_class['Class'] = labelencoder.fit_transform(df_class['Class'])\n",
    "df_class.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "\n",
    "def SVM(x,y,z):\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=z)\n",
    "    svc = LinearSVC(C=0.1)\n",
    "    svc.fit(X_train, Y_train)\n",
    "    y_pred = svc.predict(X_test)\n",
    "    #y_true = Y_test\n",
    "    \n",
    "    class_report = classification_report(Y_test, y_pred)\n",
    "    matrik = confusion_matrix(Y_test, y_pred)\n",
    "    akurasi = accuracy_score(Y_test, y_pred)\n",
    "    presisi = precision_score(Y_test, y_pred)\n",
    "    recall = recall_score(Y_test, y_pred)\n",
    "    f1score = f1_score(Y_test, y_pred)\n",
    "    print(\"Confusion Matrix : \\n\",matrik)\n",
    "    print(\"Classification Report : \\n\", class_report)\n",
    "    print(\"Accuracy  : \", akurasi)\n",
    "    print(\"Precision : \",presisi)\n",
    "    print(\"Recall    : \",recall)\n",
    "    print(\"F1 Score  : \",f1score)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================== SVM ===========================\n",
      " \n",
      "Hasil ke- 1\n",
      "Confusion Matrix : \n",
      " [[936 106]\n",
      " [160 856]]\n",
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.88      1042\n",
      "           1       0.89      0.84      0.87      1016\n",
      "\n",
      "    accuracy                           0.87      2058\n",
      "   macro avg       0.87      0.87      0.87      2058\n",
      "weighted avg       0.87      0.87      0.87      2058\n",
      "\n",
      "Accuracy  :  0.8707482993197279\n",
      "Precision :  0.8898128898128899\n",
      "Recall    :  0.84251968503937\n",
      "F1 Score  :  0.865520728008089\n",
      "\n",
      "Hasil ke- 2\n",
      "Confusion Matrix : \n",
      " [[973 103]\n",
      " [188 794]]\n",
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87      1076\n",
      "           1       0.89      0.81      0.85       982\n",
      "\n",
      "    accuracy                           0.86      2058\n",
      "   macro avg       0.86      0.86      0.86      2058\n",
      "weighted avg       0.86      0.86      0.86      2058\n",
      "\n",
      "Accuracy  :  0.858600583090379\n",
      "Precision :  0.8851727982162765\n",
      "Recall    :  0.8085539714867617\n",
      "F1 Score  :  0.8451303885045237\n",
      "\n",
      "Hasil ke- 3\n",
      "Confusion Matrix : \n",
      " [[966  92]\n",
      " [154 846]]\n",
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.89      1058\n",
      "           1       0.90      0.85      0.87      1000\n",
      "\n",
      "    accuracy                           0.88      2058\n",
      "   macro avg       0.88      0.88      0.88      2058\n",
      "weighted avg       0.88      0.88      0.88      2058\n",
      "\n",
      "Accuracy  :  0.880466472303207\n",
      "Precision :  0.9019189765458422\n",
      "Recall    :  0.846\n",
      "F1 Score  :  0.8730650154798761\n",
      "\n",
      "Hasil ke- 4\n",
      "Confusion Matrix : \n",
      " [[955  92]\n",
      " [169 842]]\n",
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88      1047\n",
      "           1       0.90      0.83      0.87      1011\n",
      "\n",
      "    accuracy                           0.87      2058\n",
      "   macro avg       0.88      0.87      0.87      2058\n",
      "weighted avg       0.88      0.87      0.87      2058\n",
      "\n",
      "Accuracy  :  0.8731778425655977\n",
      "Precision :  0.9014989293361885\n",
      "Recall    :  0.8328387734915925\n",
      "F1 Score  :  0.8658097686375321\n",
      "\n",
      "Hasil ke- 5\n",
      "Confusion Matrix : \n",
      " [[980  81]\n",
      " [174 823]]\n",
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.88      1061\n",
      "           1       0.91      0.83      0.87       997\n",
      "\n",
      "    accuracy                           0.88      2058\n",
      "   macro avg       0.88      0.87      0.88      2058\n",
      "weighted avg       0.88      0.88      0.88      2058\n",
      "\n",
      "Accuracy  :  0.8760932944606414\n",
      "Precision :  0.9103982300884956\n",
      "Recall    :  0.8254764292878636\n",
      "F1 Score  :  0.8658600736454497\n"
     ]
    }
   ],
   "source": [
    "rasio = 0.1\n",
    "print('=========================== SVM ===========================')\n",
    "print(\" \")\n",
    "print(\"Hasil ke- 1\")\n",
    "SVM(data_unigram.to_numpy(),df_class,rasio)\n",
    "print(\"\")\n",
    "print(\"Hasil ke- 2\")\n",
    "SVM(data_unigram.to_numpy(),df_class,rasio)\n",
    "print(\"\")\n",
    "print(\"Hasil ke- 3\")\n",
    "SVM(data_unigram.to_numpy(),df_class,rasio)\n",
    "print(\"\")\n",
    "print(\"Hasil ke- 4\")\n",
    "SVM(data_unigram.to_numpy(),df_class,rasio)\n",
    "print(\"\")\n",
    "print(\"Hasil ke- 5\")\n",
    "SVM(data_unigram.to_numpy(),df_class,rasio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "\n",
    "def RF(x,y,z):\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=z)\n",
    "    RandomForest = RandomForestClassifier(random_state=0)\n",
    "    RandomForest.fit(X_train, Y_train)\n",
    "    y_pred = RandomForest.predict(X_test)\n",
    "    y_true = Y_test\n",
    "    \n",
    "    class_report = classification_report(y_true, y_pred)\n",
    "    matrik = confusion_matrix(y_true, y_pred)\n",
    "    akurasi = accuracy_score(y_true, y_pred)\n",
    "    presisi = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1score = f1_score(y_true, y_pred)\n",
    "    print(\"Confusion Matrix : \\n\",matrik)\n",
    "    print(\"Classification Report : \\n\", class_report)\n",
    "    print(\"Accuracy  : \", akurasi)\n",
    "    print(\"Precision : \",presisi)\n",
    "    print(\"Recall    : \",recall)\n",
    "    print(\"F1 Score  : \",f1score)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================== Random Forest ===========================\n",
      " \n",
      "Hasil ke- 1\n",
      "Confusion Matrix : \n",
      " [[965  85]\n",
      " [150 858]]\n",
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89      1050\n",
      "           1       0.91      0.85      0.88      1008\n",
      "\n",
      "    accuracy                           0.89      2058\n",
      "   macro avg       0.89      0.89      0.89      2058\n",
      "weighted avg       0.89      0.89      0.89      2058\n",
      "\n",
      "Accuracy  :  0.8858114674441205\n",
      "Precision :  0.9098621420996819\n",
      "Recall    :  0.8511904761904762\n",
      "F1 Score  :  0.8795489492567913\n",
      "\n",
      "Hasil ke- 2\n",
      "Confusion Matrix : \n",
      " [[987 104]\n",
      " [151 816]]\n",
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.89      1091\n",
      "           1       0.89      0.84      0.86       967\n",
      "\n",
      "    accuracy                           0.88      2058\n",
      "   macro avg       0.88      0.87      0.88      2058\n",
      "weighted avg       0.88      0.88      0.88      2058\n",
      "\n",
      "Accuracy  :  0.8760932944606414\n",
      "Precision :  0.8869565217391304\n",
      "Recall    :  0.843846949327818\n",
      "F1 Score  :  0.8648648648648649\n",
      "\n",
      "Hasil ke- 3\n",
      "Confusion Matrix : \n",
      " [[949 111]\n",
      " [132 866]]\n",
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89      1060\n",
      "           1       0.89      0.87      0.88       998\n",
      "\n",
      "    accuracy                           0.88      2058\n",
      "   macro avg       0.88      0.88      0.88      2058\n",
      "weighted avg       0.88      0.88      0.88      2058\n",
      "\n",
      "Accuracy  :  0.8819241982507289\n",
      "Precision :  0.8863868986693961\n",
      "Recall    :  0.8677354709418837\n",
      "F1 Score  :  0.8769620253164556\n",
      "\n",
      "Hasil ke- 4\n",
      "Confusion Matrix : \n",
      " [[947  97]\n",
      " [134 880]]\n",
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89      1044\n",
      "           1       0.90      0.87      0.88      1014\n",
      "\n",
      "    accuracy                           0.89      2058\n",
      "   macro avg       0.89      0.89      0.89      2058\n",
      "weighted avg       0.89      0.89      0.89      2058\n",
      "\n",
      "Accuracy  :  0.8877551020408163\n",
      "Precision :  0.9007164790174002\n",
      "Recall    :  0.8678500986193294\n",
      "F1 Score  :  0.8839779005524863\n",
      "\n",
      "Hasil ke- 5\n",
      "Confusion Matrix : \n",
      " [[914 105]\n",
      " [170 869]]\n",
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87      1019\n",
      "           1       0.89      0.84      0.86      1039\n",
      "\n",
      "    accuracy                           0.87      2058\n",
      "   macro avg       0.87      0.87      0.87      2058\n",
      "weighted avg       0.87      0.87      0.87      2058\n",
      "\n",
      "Accuracy  :  0.8663751214771623\n",
      "Precision :  0.8921971252566735\n",
      "Recall    :  0.836381135707411\n",
      "F1 Score  :  0.8633879781420766\n"
     ]
    }
   ],
   "source": [
    "rasio = 0.1\n",
    "print('=========================== Random Forest ===========================')\n",
    "print(\" \")\n",
    "print(\"Hasil ke- 1\")\n",
    "RF(data_unigram.to_numpy(),df_class,rasio)\n",
    "print(\"\")\n",
    "print(\"Hasil ke- 2\")\n",
    "RF(data_unigram.to_numpy(),df_class,rasio)\n",
    "print(\"\")\n",
    "print(\"Hasil ke- 3\")\n",
    "RF(data_unigram.to_numpy(),df_class,rasio)\n",
    "print(\"\")\n",
    "print(\"Hasil ke- 4\")\n",
    "RF(data_unigram.to_numpy(),df_class,rasio)\n",
    "print(\"\")\n",
    "print(\"Hasil ke- 5\")\n",
    "RF(data_unigram.to_numpy(),df_class,rasio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
